---
title: "Correlation test"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

### Imported dataset

```{r setup, include=FALSE}
library(haven)
library(tidyverse)

ces2021 <- read_dta("dataverse_files/2021 Canadian Election Study v2.0.dta")
```

```{r}
ces2021_converted <- ces2021 %>% mutate(across(where(is.labelled), as_factor))
head(ces2021_converted)
```

### Feature Selected

Since the original dataset contains over 1000 columns, A subset of variables was selected as candidate features for building a predictive model.

```{r}
target_var <- "pes21_votechoice2021"
mia_vars <- c("pes21_province", "cps21_age", "pes21_follow_pol", "pes21_rural_urban", 
              "pes21_inequal", "pes21_abort2", "pes21_contact1", "Region", "cps21_marital",
              "cps21_imm_year", "cps21_bornin_canada", "cps21_rel_imp", "cps21_volunteer")

extra_vars <- c("Duration__in_seconds_","pes21_lived")

# Merge selected variables
feature_vars <- unique(c(mia_vars, extra_vars))

ces_selected <- ces2021_converted %>% select(target_var, all_of(feature_vars))
head(ces_selected)
```

Before modeling, we examine the distribution and potential correlations of these features to decide whether they should be included in the model.

Here is the code used to inspect the unique data entries for each selected feature.
By reviewing these values, we can identify issues like missing data, inconsistent formatting,or unexpected categories — which indicates that data cleaning is needed before analysis.

```{r}
# return unique entry for each feature
get_feature_levels <- function(data, column_name) {
  if (!column_name %in% names(data)) {
    stop("Column not found in dataset.")
  }
  unique_values <- unique(data[[column_name]])
  return(unique_values)
}
```

```{r}
#get_feature_levels(ces2021_converted, "pes21_follow_pol")

for (var in feature_vars) {
  cat("\n---", var, "---\n")
  print(get_feature_levels(ces2021_converted, var))
}
```
Since these features are of different types and most of them are non-numeric. We cannot apply a single, unified statistical method. 
Instead, we need to adopt different analysis strategies based on the nature of each variable.

### Pre-step for Correlation test

We are beginning with data cleaning as the first step, focusing on handling ambiguous responses such as NA and "don't know". In parallel, we aim to identify patterns of political apathy, which may be reflected through missing values, neutral responses, or lack of engagement.


```{r}
# Replace all "Don't know / Prefer not to answer" with NA (applies to character or factor columns)
replace_dontknow_with_na <- function(col) {
  if (is.character(col) || is.factor(col)) {
    col <- as.character(col)
    col[col %in% c("Don't know / Prefer not to answer", "Don’t know / Prefer not to answer")] <- NA
    return(as.factor(col))
  } else {
    return(col)
  }
}

# Apply the function to all columns
ces_cleaned <- ces_selected %>% mutate(across(everything(), replace_dontknow_with_na))
head(ces_cleaned)
```

Based on survey duration time, we identified some responses as unreliable.
These cases are also labeled as politically disengaged.
Since they may bias the model, we temporarily remove them from the dataset before modeling.

```{r}
library(ggplot2)
ggplot(ces2021, aes(x = Duration__in_seconds_)) +
  geom_histogram(binwidth = 10) +
  xlim(0, 2400) +  
  labs(title = "Distribution of Survey Duration",
       x = "Duration (seconds)", y = "Count")

summary(ces2021$Duration__in_seconds_)
```
The summary statistics of the `Duration` variable are as follows:

- **Minimum**: 362 seconds (~6 minutes)  
- **1st Quartile (Q1)**: 995 seconds (~16.6 minutes)  
- **Median**: 1325 seconds (~22 minutes)  
- **Mean**: 8710 seconds (significantly inflated by outliers)  
- **3rd Quartile (Q3)**: 1875 seconds (~31.3 minutes)  
- **Maximum**: 1,575,155 seconds (> 400 hours)

According to the summary, These values suggest that while most respondents completed the survey in under 30 minutes, there are a few extreme outliers with excessively long durations that strongly distort the mean.

The **minimum value of 362 seconds** and the **Q1 value of 995 seconds** suggest that any respondent completing the survey in under 10 minutes may not have engaged meaningfully with the content. Similarly, values above 48 hour are highly suspicious and may indicate participants who were inactive for long periods.

Therefore, a threshold of **600 seconds (10 minutes)** was chosen to identify "too fast" respondents, while an upper cap of **172800 seconds (48 hour)** was applied to identify "too slow" responses.

```{r}
classify_engagement <- function(data, duration_col = "Duration__in_seconds_", 
                                fast_threshold = 600, slow_threshold = 172800) {
  data <- data %>%
    mutate(
      engagement_group = case_when(
        .data[[duration_col]] < fast_threshold ~ "too_fast",
        .data[[duration_col]] > slow_threshold ~ "too_slow",
        TRUE ~ "normal"
      )
    )
  
  low_engagement_data <- data %>% filter(engagement_group != "normal")
  main_cleaned_data <- data %>% filter(engagement_group == "normal")
  
  return(list(
    full_with_labels = data,
    low_engagement = low_engagement_data,
    main_clean = main_cleaned_data
  ))
}
```

```{r}
result <- classify_engagement(ces_cleaned)

ces_selected_engag <- result$full_with_labels
low_engagement_data <- result$low_engagement # for low engagement analysis
main_cleaned_data <- result$main_clean # for correlation test
```

Next, we divide the selected features into two groups based on their data types:
- Categorical features will be tested using Cramér's V
- Ordinal or continuous features will be tested using the Kruskal-Wallis test
This helps us evaluate the strength of correlation between each feature and the target variable.

```{r}
# Initialize lists for variable classification
list_chi <- c()
list_kruskal <- c()

# Target variable (e.g. party vote choice)
target <- main_cleaned_data[[target_var]]
is_target_cat <- is.factor(target) || is.character(target)

# Loop through feature variables
if (is_target_cat) {
  for (var in feature_vars) {
    x <- main_cleaned_data[[var]]
    
    if (is.factor(x) || is.character(x)) {
      list_chi <- c(list_chi, var)
    } else if (is.numeric(x) || is.ordered(x)) {
      list_kruskal <- c(list_kruskal, var)
    }
  }
}

# Print results
cat("Variables for Cramér's V (categorical):\n")
print(list_chi)

cat("\nVariables for Kruskal-Wallis (numeric or ordered):\n")
print(list_kruskal)
```
### Correlation Test

For the features in list_chi, we compute their correlation with the target variable (party vote choice) using Cramér's V. The calculation uses the cramerV() function from the rcompanion package, which automatically removes observations with missing values (NA).


```{r}
library(rcompanion)  # cramerV
cramer_results <- data.frame(Variable = character(),
                             CramersV = numeric(),
                             stringsAsFactors = FALSE)

for (var in list_chi) {
  tbl <- table(main_cleaned_data[[target_var]], main_cleaned_data[[var]])
  if (min(dim(tbl)) > 1) {
    result <- cramerV(tbl, bias.correct = TRUE)
    cramer_results <- rbind(cramer_results, data.frame(Variable = var, CramersV = result))
  }
}

# print result
cramer_results <- cramer_results[order(-cramer_results$CramersV), ]
print(cramer_results, row.names = FALSE)

```

Higher Cramér's V values indicate stronger associations with the target variable.
Variables such as Region and Province showed relatively strong correlations with vote choice, while others like Volunteer activity and Immigration year had weaker or missing correlations.

During the Cramér's V analysis, we found that 'cps21_imm_year' returned NaN. It might because the 'cps21_imm_year' variable has many unique values (immigration years).
To address this, we converted 'cps21_imm_year' into 'years since immigration' by subtracting it from 2021.
This transformed variable is numeric and can be meaningfully analyzed using the Kruskal–Wallis test.

```{r}
# convert new variable
main_cleaned_data$imm_duration <- 2021 - as.numeric(main_cleaned_data$cps21_imm_year)

# add to list_kruskal
list_kruskal <- c(list_kruskal, "imm_duration")
```


Then we applied the Kruskal–Wallis test to evaluate whether the distributions of features in list_kruskal differ significantly across vote choice categories.

```{r}
kruskal_results <- data.frame(Variable = character(),
                              KruskalP = numeric(),
                              stringsAsFactors = FALSE)

for (var in list_kruskal) {
  df <- na.omit(main_cleaned_data[, c(var, target_var)])
  formula <- as.formula(paste(var, "~", target_var))
  result <- kruskal.test(formula, data = df)
  
  kruskal_results <- rbind(kruskal_results,
                           data.frame(Variable = var,
                                      KruskalP = result$p.value))
}

# print result
kruskal_results <- kruskal_results[order(kruskal_results$KruskalP), ]
print(kruskal_results)

```

Since small p-values indicate strong evidence of differences between groups.
The features 'cps21_age', 'Duration__in_seconds_', and 'imm_duration' all represented that these features are highly associated with voting behavior and may be valuable for predictive modeling.

We will use the following features in the prediction model:
```{r}
# filter variables with Cramér's V > 0.1
selected_cramer_vars <- cramer_results %>%
  filter(CramersV > 0.1) %>%
  pull(Variable)

# filter variables with kruskal < 0.05
selected_kruskal_vars <- kruskal_results %>%
  filter(KruskalP < 0.05) %>%
  pull(Variable)

selected_model_vars <- unique(c(selected_cramer_vars, selected_kruskal_vars))
print(selected_model_vars)
```

### Checking Feature Redundancy

To prevent multicollinearity in the model, we calculated pairwise Cramér’s V scores among features to identify strongly correlated variables.

Interpretation thresholds:
• V > 0.6 — High correlation: likely redundant; consider removing one of the variables.
• V > 0.4 — Moderate correlation: possible redundancy; proceed with caution.
• V < 0.3 — Low correlation: safe to include both variables.


```{r}
library(rcompanion)

feature_corr_results <- data.frame(VarA = character(),
                                   VarB = character(),
                                   CramersV = numeric(),
                                   stringsAsFactors = FALSE)

for (i in 1:(length(selected_cramer_vars)-1)) {
  for (j in (i+1):length(selected_cramer_vars)) {
    varA <- selected_cramer_vars[i]
    varB <- selected_cramer_vars[j]

    clean_data <- main_cleaned_data %>%
      dplyr::select(all_of(c(varA, varB))) %>%
      dplyr::filter(!is.na(.data[[varA]]), !is.na(.data[[varB]]))

    tbl <- table(clean_data[[varA]], clean_data[[varB]])

    if (min(dim(tbl)) > 1) {
      result <- cramerV(tbl, bias.correct = TRUE)
      feature_corr_results <- rbind(feature_corr_results,
                                    data.frame(VarA = varA, VarB = varB, CramersV = result))
    }
  }
}

# print out
feature_corr_results <- feature_corr_results %>%
  mutate(Explanation = case_when(
    CramersV > 0.6 ~ "High correlation – consider removing one variable",
    CramersV > 0.4 ~ "Moderate correlation – possible redundancy",
    TRUE ~ "Low correlation – likely safe to include both"
  ))

feature_corr_results <- feature_corr_results[order(-feature_corr_results$CramersV), ]
print(feature_corr_results)
```


Among all feature pairs, only `Region` and `pes21_province` showed a high Cramér’s V (0.9997), indicating near-perfect redundancy. Since both represent geographic information.
We will retain only one of them to avoid duplication. In this case, we choose to keep `pes21_province`.

### Result

Update the list of features in the prediction model:
```{r}
selected_cramer_vars <- setdiff(selected_cramer_vars, "Region")
selected_model_vars <- unique(c(selected_cramer_vars, selected_kruskal_vars))
print(selected_model_vars)
```